# Prerequisites Before Gremlin Implementation

After completing both task lists documented in your reference materials, the architecture requires no additional changes before Gremlin implementation can commence. The data collection pipeline is complete, the derivation functions generate all necessary edges, and the data model supports graph projection without modification.

The current architecture collects all entities and relationships required for attack path analysis. The twelve collectors gather users with embedded risk and license data, groups with type categorization, service principals, devices, applications with permission analysis from MSGraphPermissions integration, Azure resources across eleven types, role definitions for both directory and Azure scopes, Conditional Access policies, role management policies with extracted settings, PIM group policies, Intune compliance and app protection policies including Windows MAM, administrative units with scoped role assignments, and named locations. The events collector captures sign-ins and audit logs though you have identified the need to define selective filtering criteria to prevent storage explosion from unbounded audit log collection.

The relationship collection encompasses the full taxonomy of thirty-three base edge types including group memberships both direct and transitive, group ownership, directory role assignments, PIM eligibility and active assignments for both roles and groups, Azure RBAC assignments, application role assignments, OAuth2 permission grants, license assignments, device ownership, application and service principal ownership, managed identity links from Azure resources to service principals, Key Vault access policies, Azure hierarchy containment, Conditional Access policy targeting and exclusions for both principals and applications, Conditional Access location condition references, role management policy assignments to roles, and PIM activation requests with justification text. The derivation functions add six abuse edge types representing concrete attack capabilities derived from dangerous permissions and directory role assignments plus two virtual edge types materializing Intune policy targeting relationships.

The data model uses consistent type discriminators across all six containers enabling straightforward mapping to graph database vertex and edge labels. The principals container discriminates by principal type with values for user, group, service principal, and device. The resources container discriminates by resource type covering applications, directory and Azure role definitions, tenant metadata, management groups, subscriptions, resource groups, and the eleven Azure resource types. The edges container discriminates by edge type for all relationship categories. The policies container discriminates by policy type for the various policy categories. This discriminator pattern translates directly to Gremlin vertex labels and edge labels without requiring schema transformation or data reshaping.

The temporal tracking fields exist on all entities and edges enabling historical path reconstruction showing which attack paths existed at specific points in time. The effectiveFrom timestamp records when entities appear or relationships form while effectiveTo remains null for active state and receives a timestamp when entities are deleted or relationships terminate. This temporal model supports soft delete semantics in the graph database where vertices and edges persist with effectiveTo values set rather than physical deletion removing them from the graph. Historical attack path queries can filter for entities and relationships active during specific time periods by checking whether the query timestamp falls between effectiveFrom and effectiveTo boundaries.

The audit container maintains permanent change history with no time-to-live expiration providing the change stream necessary for incremental graph synchronization. Every modification to principals, resources, edges, or policies generates an audit record containing the change timestamp, change type indicating new versus modified versus deleted, the entity type and identifier, and for modifications the specific fields that changed with their new values. This audit stream enables the watermark-based synchronization pattern where the projection function processes only changes occurring after the last successful synchronization avoiding full graph rebuilds on every execution.

The denormalization strategy embedding display names in relationship documents ensures the graph database can present human-readable path visualizations without requiring joins back to entity containers to resolve object identifiers. When an edge document contains source display name and target display name alongside source identifier and target identifier, the Gremlin projection can populate edge properties with these display names enabling attack path snapshots to show comprehensible entity names rather than opaque GUIDs. This denormalization decision made during initial architecture design pays dividends for graph database consumption eliminating complex enrichment logic during projection.

The MSGraphPermissions integration adds permission analysis edges connecting applications to their Graph API permissions with metadata distinguishing dangerous permissions from merely high-privilege permissions. These edges enhance attack path discovery by revealing which applications hold broad permissions creating attack surface. The permission metadata includes endpoint counts showing how many Graph API endpoints each permission grants access to, enabling blast radius analysis for credential theft scenarios where compromised application credentials provide access to the endpoints covered by granted permissions.

The role definitions exist as synthetic vertices in the resources container with isPrivileged flags computed from the privileged role lists in your configuration. This enables path traversal through roles where discovering a path from user to role assignment edge to role definition vertex immediately indicates privilege level through the isPrivileged property without requiring separate privilege lookup after path discovery. The role definition vertices bridge directory role assignments and Azure RBAC assignments through a common vertex type that Gremlin traversals can navigate uniformly regardless of whether privilege derives from Entra ID roles or Azure resource roles.

The architecture contains no missing data collection components, no incomplete derivation logic, and no data model deficiencies that would prevent graph database implementation. The task list completion delivers comprehensive entity and relationship coverage with temporal tracking, audit history, denormalized display names, permission analysis, and role definition vertices. Gremlin implementation can proceed immediately upon task list completion without requiring architectural changes or additional data collection phases.​​​​​​​​​​​​​​​​

## 1. Readiness After Completing Both Task Lists

After completing all items in claude-to-do-reference.md and the MSGraphPermissions Integration Plan, the platform will be fully ready for Gremlin implementation. Nothing additional is required.

The task list completion delivers comprehensive edge collection including the thirty-three base edge types, six abuse edges from DeriveEdges, two virtual edges from DeriveVirtualEdges, and the new permission analysis edges from MSGraphPermissions integration. The audit container contains complete change history with temporal tracking on all entities. The dashboard displays all entity types, relationships, and policies with proper column ordering and human-friendly GUID resolution.

The MSGraphPermissions integration adds the appHasDangerousPermission and appHasHighPrivilegePermission edge types that enhance attack path discovery by connecting applications to their Graph API permissions. The permission analysis provides context showing which applications hold broad permissions that create attack surface beyond just the dangerous permissions list.

All collectors are operational including the configuration-driven Azure resource collection, unified role definitions collection, comprehensive Intune policy collection with Windows MAM support, PIM justification capture, and all missing policies from the analysis. The derivation functions generate abuse edges and virtual policy targeting edges. The indexers handle delta detection with the ninety-nine percent write reduction working correctly across all container types.

Your data model is complete with all discriminator fields populated correctly, temporal fields tracking entity lifecycles, embedded display names eliminating GUID opacity, and relationship denormalization supporting efficient queries. The blob storage contains the five unified JSONL files per collection run providing fallback access to raw data if needed.

## 2. Gremlin Implementation Approach

The implementation follows the architecture already documented in your README version three point five. You have defined the complete approach including watermark-based synchronization, fold and coalesce upsert patterns, vertex and edge schema, partition key strategy, and snapshot generation queries.

### Infrastructure Provisioning

Create a separate Cosmos DB account with Gremlin API enabled since Cosmos DB requires separate accounts for SQL and Gremlin APIs. Provision this account in the same Azure region as your existing SQL Cosmos account to minimize latency. Use the account name format following your existing naming convention, potentially cosmos-entrarisk-gremlin-env-suffix to distinguish it from the SQL account.

Create the database named EntraGraph and the graph container named graph with partition key set to forward slash pk. Configure the container with appropriate throughput allocation. Your architecture does not specify provisioned versus serverless but given the fifteen-minute synchronization schedule and hourly snapshot generation, provisioned throughput with autoscale may provide better cost predictability than serverless consumption.

Grant the Function App managed identity appropriate permissions to access the Gremlin account. Store the Gremlin connection string in Azure Key Vault and reference it through Function App application settings using Key Vault references. Update your infrastructure as code in the deploy script to provision these resources consistently across environments.

### ProjectGraphToGremlin Function Implementation

Create the new Azure Function with timer trigger running every fifteen minutes using cron expression zero forward slash fifteen asterisk asterisk asterisk asterisk. The function queries the audit container for changes since the last watermark timestamp, projects vertices and edges to Gremlin, and updates the watermark.

Implement watermark storage using a dedicated Cosmos SQL container named sync-state with documents tracking last successful synchronization timestamp per tenant. The watermark document structure should include tenant identifier, last sync timestamp, last successful run timestamp, consecutive failure count, and last error message.

The vertex projection logic reads audit records from the principals and resources containers, extracts entity type from the container name and type discriminator field, and constructs Gremlin upsert commands. Use the fold and coalesce pattern documented in your architecture where the query checks for vertex existence by identifier, either returns the existing vertex or creates a new vertex with required properties.

The edge projection logic processes audit records from the edges container, constructs edge upserts using coalesce to check for existing edges matching source identifier, target identifier, and edge type, then either returns the existing edge or creates new edge. Copy all edge properties from the audit record to the Gremlin edge to preserve relationship metadata like justification text on pimRequest edges or policy settings on rolePolicyAssignment edges.

Handle soft deletes by setting effectiveTo property on vertices and edges rather than removing them from the graph. This preserves historical attack paths showing what privilege escalation routes existed at specific points in time even after relationships are removed from active state.

Implement batching logic to process audit records in groups preventing memory exhaustion when large numbers of changes accumulate between synchronization runs. Process vertices before edges to ensure target vertices exist before creating edges referencing them. Include error handling with retry logic for transient Gremlin API failures and dead letter queue for records that fail repeatedly after maximum retry attempts.

Log comprehensive metrics to Application Insights including synchronization duration, watermark advancement amount, vertex count processed, edge count processed, error count, and whether synchronization completed successfully. These metrics support monitoring and alerting for synchronization health.

### GenerateGraphSnapshots Function Implementation

Create the Azure Function with timer trigger running hourly using cron expression zero zero asterisk asterisk asterisk asterisk. The function executes the seven predefined Gremlin traversals for attack path snapshots, generates DOT and JSON output files, and uploads results to blob storage.

Implement each snapshot query as documented in your architecture specification. The paths to global administrator query traverses incoming edges from the Global Administrator role definition vertex using repeat step with simplePath constraint and emit to capture all intermediate paths. The dangerous service principals query filters service principal vertices with outbound hasRole edges to privileged role definition vertices. The external user exposure query starts from guest user vertices and traverses until reaching privileged roles.

Generate JSON output containing snapshot metadata including name, title, description, generation timestamp, path count, and the array of discovered paths with full vertex and edge details. Generate DOT format output with Graphviz syntax including graph declaration, node definitions with appropriate styling based on vertex types, and edge definitions with labels from edge types.

Upload both files to blob storage in the snapshots subdirectory using naming convention snapshot-name.json and snapshot-name.dot. Generate manifest.json aggregating metadata across all snapshots including total generation timestamp, snapshot count, total path count across all snapshots, error count, and array of per-snapshot summaries.

Implement timeout logic for expensive graph traversals to prevent single snapshot query from consuming excessive execution time. Handle empty result sets gracefully when no paths exist for particular query pattern. Include error handling that allows other snapshots to generate successfully even if one snapshot query fails.

### Dashboard Integration

Add attack paths section to the dashboard after the policies section. Query blob storage for the manifest.json file to retrieve snapshot metadata. Display cards for each snapshot type showing name, description, path count, and generation timestamp. Provide download links to the DOT and JSON files for each snapshot enabling users to analyze results in external graph visualization tools.

Browser-based graph rendering requires selecting and integrating a JavaScript graph visualization library capable of parsing DOT format or consuming the JSON path representation. This adds significant frontend complexity compared to the download-based approach. Given your current dashboard implementation using server-side HTML generation, the download approach maintains architectural consistency and simplicity.

### Monitoring and Operations

Create Application Insights queries tracking ProjectGraphToGremlin synchronization metrics including average synchronization duration, watermark lag calculated as current time minus last watermark timestamp, synchronization failure rate, and vertex and edge processing rates. Establish alert rules triggering when synchronization lag exceeds fifteen minutes indicating the projection function has fallen behind collection rate or when consecutive failures exceed threshold indicating systematic issues requiring intervention.

Document operational procedures for common scenarios including manual watermark reset if graph database corruption requires rebuild from audit history, Gremlin account throughput scaling if query performance degrades, and snapshot query optimization if generation duration exceeds acceptable boundaries.

The implementation delivers the Gremlin graph database with incremental synchronization from your audit container, pre-computed attack path snapshots, and dashboard integration for snapshot access. This completes the attack path discovery capability enabling security teams to visualize privilege escalation routes and identify security gaps through graph traversal analysis.​​​​​​​​​​​​​​​​

# Architecture Gaps for Gremlin Implementation

After completing both task lists, the architecture contains no missing data collection or derivation components required for Gremlin implementation. All thirty-three edge types are collected, the six abuse edges are derived, the two virtual policy targeting edges are generated, and the MSGraphPermissions integration adds the permission analysis edges. The audit container maintains complete change history with temporal tracking on all entities and relationships. The delta detection mechanism operates correctly across all six containers achieving the ninety-nine percent write reduction after initial collection runs.

However, the architecture lacks the operational infrastructure and function implementations that enable graph database synchronization and snapshot generation. The watermark storage mechanism does not exist. The platform needs a persistent location to store the last successful synchronization timestamp that the ProjectGraphToGremlin function reads at startup and updates after successful completion. Without this watermark mechanism, the projection function cannot determine which audit records represent new changes requiring synchronization to the graph database versus historical records already processed in previous runs.

The ProjectGraphToGremlin function itself does not exist in the current codebase. The architecture specification documents the intended behavior including reading the watermark, querying audit records, projecting vertices and edges using fold and coalesce upsert patterns, and updating the watermark after successful completion. None of this logic has been implemented. The function requires development including timer trigger configuration, watermark read and write operations, audit container queries with temporal filtering, Gremlin vertex and edge upsert commands, soft delete handling, batch processing logic, error handling with retry, and Application Insights metrics emission.

The GenerateGraphSnapshots function does not exist. The seven snapshot types are documented in the architecture specification with descriptions of their Gremlin traversal patterns, but no implementation code exists. The function needs development including the timer trigger configuration, the seven Gremlin traversal queries, JSON output generation with path metadata and vertex and edge arrays, DOT format generation with Graphviz syntax and node styling, blob upload operations, manifest file aggregation, timeout handling for expensive traversals, and error handling allowing partial success when individual snapshot queries fail.

The Gremlin Cosmos DB account has not been provisioned. The existing Cosmos DB account uses SQL API which cannot coexist with Gremlin API in the same account. A separate Cosmos DB account with Gremlin API enabled must be provisioned in the same Azure region as the existing SQL account. The database and graph container must be created with partition key configured as forward slash pk and throughput allocation established through either provisioned or serverless mode. The Function App managed identity requires permission grants to access the new Gremlin account, and connection string storage in Key Vault with Function App application settings configured to reference the Key Vault secret.

The dashboard lacks the attack paths section for snapshot visualization. The current dashboard displays principals, resources, edges, policies, and audit records but does not include a section for browsing available snapshots or downloading snapshot files. The dashboard requires new HTML section with cards displaying snapshot metadata read from the manifest file including snapshot name, description, path count, and generation timestamp. Download links to DOT and JSON files enable users to analyze results in external graph visualization tools. This section integration fits after the policies section in the navigation structure following the architectural pattern established for other container displays.

The monitoring and alerting infrastructure for graph synchronization health does not exist. Application Insights queries for tracking synchronization metrics including duration, watermark lag, vertex and edge processing counts, and error rates require definition. Alert rules triggering when synchronization lag exceeds thresholds or consecutive failures indicate systematic issues need configuration in Azure Monitor. Operational runbooks documenting procedures for manual watermark reset, Gremlin account throughput scaling, and snapshot query optimization require creation. Without this operational infrastructure, synchronization failures could persist undetected until users notice stale data in attack path snapshots.

The infrastructure as code scripts do not include Gremlin account provisioning. The deployment automation currently provisions the SQL Cosmos DB account, storage account, Function App, Application Insights, and Key Vault. The scripts need extension to provision the Gremlin Cosmos DB account, create the database and graph container, configure throughput settings, establish network connectivity, grant managed identity permissions, and store connection strings in Key Vault. Without infrastructure as code updates, the Gremlin components cannot deploy consistently across development, staging, and production environments.

These gaps represent implementation work rather than architectural design deficiencies. The data model supports graph projection without modification. The edge types map cleanly to Gremlin edge labels. The temporal fields enable historical path reconstruction. The audit container provides the change stream necessary for incremental synchronization. Completing the two task lists delivers all prerequisite data collection and derivation capabilities. The remaining work involves building the operational components that consume that data to populate and maintain the graph database.​​​​​​​​​​​​​​​​